{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import affine_transform, shift\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from typing import Tuple, List\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_mnist_data() -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Loads the MNIST dataset from Keras.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        A tuple containing:\n",
    "            - train_images (np.ndarray): Array of shape (60000, 28, 28)\n",
    "            - train_labels (np.ndarray): Array of shape (60000,)\n",
    "            - test_images  (np.ndarray): Array of shape (10000, 28, 28)\n",
    "            - test_labels  (np.ndarray): Array of shape (10000,)\n",
    "    \"\"\"\n",
    "    (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def deskew_image(img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Deskews a single 28x28 grayscale digit image using moment analysis.\n",
    "    \n",
    "    Args:\n",
    "        img (np.ndarray): A 28x28 grayscale image array.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A deskewed 28x28 image array.\n",
    "    \"\"\"\n",
    "    # Compute the image moments\n",
    "    y, x = np.indices(img.shape)\n",
    "    total_mass = img.sum()\n",
    "    if total_mass == 0:\n",
    "        return img  # Avoid division by zero\n",
    "\n",
    "    x_center = (x * img).sum() / total_mass\n",
    "    y_center = (y * img).sum() / total_mass\n",
    "\n",
    "    # Compute second-order central moments\n",
    "    mu_xx = ((x - x_center) ** 2 * img).sum() / total_mass\n",
    "    mu_yy = ((y - y_center) ** 2 * img).sum() / total_mass\n",
    "    mu_xy = ((x - x_center) * (y - y_center) * img).sum() / total_mass\n",
    "\n",
    "    if mu_yy == 0:\n",
    "        return img  # No skew detected\n",
    "\n",
    "    skew = mu_xy / mu_yy  # Skew factor\n",
    "\n",
    "    # Define the transformation matrix\n",
    "    M = np.array([[1, skew, -skew * x_center], [0, 1, 0]])\n",
    "\n",
    "    # Apply affine transformation\n",
    "    deskewed_img = affine_transform(img, M, offset=0, order=1, mode='constant', cval=0)\n",
    "    \n",
    "    return deskewed_img\n",
    "\n",
    "def deskew_dataset(images: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Deskews each image in an entire dataset.\n",
    "    \n",
    "    Args:\n",
    "        images (np.ndarray): A batch of images of shape (num_samples, 28, 28).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A batch of deskewed images of shape (num_samples, 28, 28).\n",
    "    \"\"\"\n",
    "    return np.array([deskew_image(img) for img in images])\n",
    "\n",
    "def jitter_image(img: np.ndarray, max_shift: int = 2) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Randomly shifts (jitters) a single 28x28 grayscale digit image.\n",
    "    \n",
    "    Args:\n",
    "        img (np.ndarray): A 28x28 grayscale image array.\n",
    "        max_shift (int, optional): Maximum pixel shift in both x and y directions. Defaults to 2.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A 28x28 image array that has been shifted randomly.\n",
    "    \"\"\"\n",
    "    shift_x = np.random.randint(-max_shift, max_shift + 1)\n",
    "    shift_y = np.random.randint(-max_shift, max_shift + 1)\n",
    "    \n",
    "    return shift(img, shift=(shift_y, shift_x), mode='constant', cval=0)\n",
    "\n",
    "def jitter_dataset(\n",
    "    images: np.ndarray, \n",
    "    labels: np.ndarray, \n",
    "    num_copies: int = 1, \n",
    "    max_shift: int = 2\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Applies jitter augmentation to an entire dataset. \n",
    "    For each image, creates additional copies with random shifts.\n",
    "    \n",
    "    Args:\n",
    "        images (np.ndarray): Image batch of shape (num_samples, 28, 28).\n",
    "        labels (np.ndarray): Label array of shape (num_samples,).\n",
    "        num_copies (int, optional): Number of jittered copies to create for each image. Defaults to 1.\n",
    "        max_shift (int, optional): Maximum pixel shift in x and y directions. Defaults to 2.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Augmented dataset and corresponding labels.\n",
    "    \"\"\"\n",
    "    augmented_images = []\n",
    "    augmented_labels = []\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        # Add original\n",
    "        augmented_images.append(images[i])\n",
    "        augmented_labels.append(labels[i])\n",
    "        \n",
    "        # Add jittered copies\n",
    "        for _ in range(num_copies):\n",
    "            jittered_img = jitter_image(images[i], max_shift)\n",
    "            augmented_images.append(jittered_img)\n",
    "            augmented_labels.append(labels[i])\n",
    "    \n",
    "    return np.array(augmented_images, dtype=np.float32), np.array(augmented_labels, dtype=np.int64)\n",
    "\n",
    "def flatten_normalize(images: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Flattens 28x28 images into 1D vectors of length 784 \n",
    "    and normalizes pixel values to the range [0, 1].\n",
    "    \n",
    "    Args:\n",
    "        images (np.ndarray): A batch of images of shape (num_samples, 28, 28).\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: A batch of flattened and normalized images \n",
    "                    of shape (num_samples, 784).\n",
    "    \"\"\"\n",
    "    return images.reshape(images.shape[0], -1) / 255.0\n",
    "\n",
    "def build_svm_classifier(kernel: str = 'poly', degree: int = 9) -> svm.SVC:\n",
    "    \"\"\"\n",
    "    Builds and returns an SVM classifier using scikit-learn's SVC with a specified kernel.\n",
    "    \n",
    "    Args:\n",
    "        kernel (str, optional): The kernel type to be used in the algorithm. Defaults to 'poly'.\n",
    "        degree (int, optional): Degree of the polynomial kernel function ('poly'). Defaults to 9.\n",
    "        \n",
    "    Returns:\n",
    "        svm.SVC: An SVM classifier with the given kernel parameters.\n",
    "    \"\"\"\n",
    "    return svm.SVC(kernel=kernel, degree=degree, gamma='auto', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM... This may take a while.\n",
      "[LibSVM]SVM (poly, degree=9) test accuracy: 92.74%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main pipeline for:\n",
    "        1. Loading and deskewing the MNIST dataset.\n",
    "        2. Augmenting the training data with random jitter.\n",
    "        3. Flattening and normalizing the image data.\n",
    "        4. Building and training a polynomial SVM (degree=9).\n",
    "        5. Evaluating on the test set.\n",
    "    \"\"\"\n",
    "    # 1. Load MNIST data\n",
    "    train_images, train_labels, test_images, test_labels = load_mnist_data()\n",
    "\n",
    "    # 2. Deskew all images\n",
    "    train_images = deskew_dataset(train_images)\n",
    "    test_images = deskew_dataset(test_images)\n",
    "\n",
    "    # 3. Apply jitter augmentation to the training set\n",
    "    # train_images_aug, train_labels_aug = jitter_dataset(train_images, train_labels, num_copies=1, max_shift=2)\n",
    "    # print(f\"Original training size: {len(train_images)}, Augmented size: {len(train_images_aug)}\")\n",
    "\n",
    "    # 4. Flatten and normalize\n",
    "    X_train = flatten_normalize(train_images) # noam: removed the _aug\n",
    "    y_train = train_labels # noam: removed the _aug\n",
    "    X_test = flatten_normalize(test_images)\n",
    "    y_test = test_labels\n",
    "\n",
    "    # 5. Build SVM classifier with polynomial kernel (degree=9)\n",
    "    classifier = build_svm_classifier(kernel='rbf')\n",
    "\n",
    "    print(\"Training SVM... This may take a while.\")\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # 6. Evaluate\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"SVM (poly, degree=9) test accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnist_sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
